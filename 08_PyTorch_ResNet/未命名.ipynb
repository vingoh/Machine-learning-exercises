{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Epoch   1/200, train loss: 1.7e-02, accuracy: 23.57%\n",
    "Epoch   1/200, val loss: 1.3e-02, accuracy: 38.72%\n",
    "Epoch   2/200, train loss: 1.2e-02, accuracy: 44.79%\n",
    "Epoch   2/200, val loss: 1.1e-02, accuracy: 51.06%\n",
    "Epoch   3/200, train loss: 9.3e-03, accuracy: 57.11%\n",
    "Epoch   3/200, val loss: 9.2e-03, accuracy: 59.40%\n",
    "Epoch   4/200, train loss: 7.5e-03, accuracy: 66.02%\n",
    "Epoch   4/200, val loss: 8.3e-03, accuracy: 65.08%\n",
    "Epoch   5/200, train loss: 6.3e-03, accuracy: 71.90%\n",
    "Epoch   5/200, val loss: 7.7e-03, accuracy: 69.28%\n",
    "Epoch   6/200, train loss: 5.5e-03, accuracy: 75.68%\n",
    "Epoch   6/200, val loss: 5.8e-03, accuracy: 76.08%\n",
    "Epoch   7/200, train loss: 5.0e-03, accuracy: 77.67%\n",
    "Epoch   7/200, val loss: 1.1e-02, accuracy: 64.12%\n",
    "Epoch   8/200, train loss: 4.6e-03, accuracy: 79.82%\n",
    "Epoch   8/200, val loss: 5.7e-03, accuracy: 78.02%\n",
    "Epoch   9/200, train loss: 4.3e-03, accuracy: 80.78%\n",
    "Epoch   9/200, val loss: 5.4e-03, accuracy: 78.16%\n",
    "Epoch  10/200, train loss: 4.1e-03, accuracy: 82.24%\n",
    "Epoch  10/200, val loss: 4.9e-03, accuracy: 80.38%\n",
    "Epoch  11/200, train loss: 3.8e-03, accuracy: 83.25%\n",
    "Epoch  11/200, val loss: 7.0e-03, accuracy: 73.26%\n",
    "Epoch  12/200, train loss: 3.6e-03, accuracy: 83.91%\n",
    "Epoch  12/200, val loss: 4.3e-03, accuracy: 82.62%\n",
    "Epoch  13/200, train loss: 3.5e-03, accuracy: 84.62%\n",
    "Epoch  13/200, val loss: 4.4e-03, accuracy: 81.74%\n",
    "Epoch  14/200, train loss: 3.3e-03, accuracy: 85.21%\n",
    "Epoch  14/200, val loss: 4.0e-03, accuracy: 83.58%\n",
    "Epoch  15/200, train loss: 3.2e-03, accuracy: 85.70%\n",
    "Epoch  15/200, val loss: 5.1e-03, accuracy: 80.40%\n",
    "Epoch  16/200, train loss: 3.2e-03, accuracy: 86.00%\n",
    "Epoch  16/200, val loss: 3.8e-03, accuracy: 85.28%\n",
    "Epoch  17/200, train loss: 3.0e-03, accuracy: 86.64%\n",
    "Epoch  17/200, val loss: 4.1e-03, accuracy: 84.16%\n",
    "Epoch  18/200, train loss: 2.9e-03, accuracy: 86.91%\n",
    "Epoch  18/200, val loss: 4.8e-03, accuracy: 82.48%\n",
    "Epoch  19/200, train loss: 2.9e-03, accuracy: 87.07%\n",
    "Epoch  19/200, val loss: 4.3e-03, accuracy: 82.94%\n",
    "Epoch  20/200, train loss: 2.7e-03, accuracy: 87.84%\n",
    "Epoch  20/200, val loss: 4.2e-03, accuracy: 84.20%\n",
    "Epoch  21/200, train loss: 2.7e-03, accuracy: 88.07%\n",
    "Epoch  21/200, val loss: 4.7e-03, accuracy: 82.32%\n",
    "Epoch  22/200, train loss: 2.7e-03, accuracy: 88.10%\n",
    "Epoch  22/200, val loss: 4.6e-03, accuracy: 82.58%\n",
    "Epoch  23/200, train loss: 2.6e-03, accuracy: 88.71%\n",
    "Epoch  23/200, val loss: 4.2e-03, accuracy: 83.78%\n",
    "Epoch  24/200, train loss: 2.5e-03, accuracy: 88.84%\n",
    "Epoch  24/200, val loss: 4.1e-03, accuracy: 84.14%\n",
    "Epoch  25/200, train loss: 2.5e-03, accuracy: 88.76%\n",
    "Epoch  25/200, val loss: 3.9e-03, accuracy: 85.38%\n",
    "Epoch  26/200, train loss: 2.4e-03, accuracy: 89.22%\n",
    "Epoch  26/200, val loss: 4.3e-03, accuracy: 83.36%\n",
    "Epoch  27/200, train loss: 2.4e-03, accuracy: 89.56%\n",
    "Epoch  27/200, val loss: 4.1e-03, accuracy: 84.46%\n",
    "Epoch  28/200, train loss: 2.3e-03, accuracy: 89.53%\n",
    "Epoch  28/200, val loss: 4.0e-03, accuracy: 85.04%\n",
    "Epoch  29/200, train loss: 2.3e-03, accuracy: 89.68%\n",
    "Epoch  29/200, val loss: 4.6e-03, accuracy: 83.10%\n",
    "Epoch  30/200, train loss: 2.3e-03, accuracy: 89.94%\n",
    "Epoch  30/200, val loss: 3.6e-03, accuracy: 86.40%\n",
    "Epoch  31/200, train loss: 2.3e-03, accuracy: 89.88%\n",
    "Epoch  31/200, val loss: 4.8e-03, accuracy: 83.62%\n",
    "Epoch  32/200, train loss: 2.2e-03, accuracy: 90.00%\n",
    "Epoch  32/200, val loss: 3.4e-03, accuracy: 87.28%\n",
    "Epoch  33/200, train loss: 2.1e-03, accuracy: 90.40%\n",
    "Epoch  33/200, val loss: 4.4e-03, accuracy: 84.12%\n",
    "Epoch  34/200, train loss: 2.1e-03, accuracy: 90.42%\n",
    "Epoch  34/200, val loss: 3.9e-03, accuracy: 84.90%\n",
    "Epoch  35/200, train loss: 2.1e-03, accuracy: 90.38%\n",
    "Epoch  35/200, val loss: 4.8e-03, accuracy: 83.10%\n",
    "Epoch  36/200, train loss: 2.1e-03, accuracy: 90.71%\n",
    "Epoch  36/200, val loss: 3.9e-03, accuracy: 86.38%\n",
    "Epoch  37/200, train loss: 2.0e-03, accuracy: 90.88%\n",
    "Epoch  37/200, val loss: 3.7e-03, accuracy: 85.94%\n",
    "Epoch  38/200, train loss: 2.0e-03, accuracy: 90.96%\n",
    "Epoch  38/200, val loss: 3.3e-03, accuracy: 87.18%\n",
    "Epoch  39/200, train loss: 2.0e-03, accuracy: 91.06%\n",
    "Epoch  39/200, val loss: 3.8e-03, accuracy: 85.70%\n",
    "Epoch  40/200, train loss: 2.0e-03, accuracy: 91.17%\n",
    "Epoch  40/200, val loss: 3.6e-03, accuracy: 85.92%\n",
    "Epoch  41/200, train loss: 1.9e-03, accuracy: 91.52%\n",
    "Epoch  41/200, val loss: 3.5e-03, accuracy: 86.92%\n",
    "Epoch  42/200, train loss: 1.9e-03, accuracy: 91.26%\n",
    "Epoch  42/200, val loss: 3.5e-03, accuracy: 86.22%\n",
    "Epoch  43/200, train loss: 1.9e-03, accuracy: 91.45%\n",
    "Epoch  43/200, val loss: 3.6e-03, accuracy: 86.58%\n",
    "Epoch  44/200, train loss: 1.9e-03, accuracy: 91.55%\n",
    "Epoch  44/200, val loss: 3.7e-03, accuracy: 86.32%\n",
    "Epoch  45/200, train loss: 1.9e-03, accuracy: 91.54%\n",
    "Epoch  45/200, val loss: 3.6e-03, accuracy: 86.08%\n",
    "Epoch  46/200, train loss: 1.8e-03, accuracy: 92.13%\n",
    "Epoch  46/200, val loss: 3.7e-03, accuracy: 85.60%\n",
    "Epoch  47/200, train loss: 1.9e-03, accuracy: 91.50%\n",
    "Epoch  47/200, val loss: 4.7e-03, accuracy: 82.78%\n",
    "Epoch  48/200, train loss: 1.8e-03, accuracy: 91.92%\n",
    "Epoch  48/200, val loss: 4.0e-03, accuracy: 85.60%\n",
    "Epoch  49/200, train loss: 1.8e-03, accuracy: 91.78%\n",
    "Epoch  49/200, val loss: 4.0e-03, accuracy: 85.34%\n",
    "Epoch  50/200, train loss: 1.8e-03, accuracy: 91.81%\n",
    "Epoch  50/200, val loss: 5.7e-03, accuracy: 81.46%\n",
    "Epoch  51/200, train loss: 1.8e-03, accuracy: 92.07%\n",
    "Epoch  51/200, val loss: 3.7e-03, accuracy: 86.40%\n",
    "Epoch  52/200, train loss: 1.8e-03, accuracy: 91.90%\n",
    "Epoch  52/200, val loss: 3.6e-03, accuracy: 86.52%\n",
    "Epoch  53/200, train loss: 1.8e-03, accuracy: 92.01%\n",
    "Epoch  53/200, val loss: 3.5e-03, accuracy: 87.62%\n",
    "Epoch  54/200, train loss: 1.7e-03, accuracy: 92.34%\n",
    "Epoch  54/200, val loss: 5.3e-03, accuracy: 82.00%\n",
    "Epoch  55/200, train loss: 1.7e-03, accuracy: 92.12%\n",
    "Epoch  55/200, val loss: 6.1e-03, accuracy: 80.34%\n",
    "Epoch  56/200, train loss: 1.7e-03, accuracy: 92.49%\n",
    "Epoch  56/200, val loss: 3.3e-03, accuracy: 87.74%\n",
    "Epoch  57/200, train loss: 1.7e-03, accuracy: 92.33%\n",
    "Epoch  57/200, val loss: 3.6e-03, accuracy: 87.12%\n",
    "Epoch  58/200, train loss: 1.7e-03, accuracy: 92.36%\n",
    "Epoch  58/200, val loss: 3.2e-03, accuracy: 88.10%\n",
    "Epoch  59/200, train loss: 1.7e-03, accuracy: 92.40%\n",
    "Epoch  59/200, val loss: 4.5e-03, accuracy: 84.16%\n",
    "Epoch  60/200, train loss: 1.7e-03, accuracy: 92.45%\n",
    "Epoch  60/200, val loss: 4.2e-03, accuracy: 85.08%\n",
    "Epoch  61/200, train loss: 1.6e-03, accuracy: 92.60%\n",
    "Epoch  61/200, val loss: 3.3e-03, accuracy: 88.40%\n",
    "Epoch  62/200, train loss: 1.7e-03, accuracy: 92.42%\n",
    "Epoch  62/200, val loss: 4.5e-03, accuracy: 83.54%\n",
    "Epoch  63/200, train loss: 1.7e-03, accuracy: 92.45%\n",
    "Epoch  63/200, val loss: 3.6e-03, accuracy: 87.38%\n",
    "Epoch  64/200, train loss: 1.6e-03, accuracy: 92.62%\n",
    "Epoch  64/200, val loss: 3.7e-03, accuracy: 87.36%\n",
    "Epoch  65/200, train loss: 1.7e-03, accuracy: 92.63%\n",
    "Epoch  65/200, val loss: 3.5e-03, accuracy: 87.20%\n",
    "Epoch  66/200, train loss: 1.6e-03, accuracy: 92.78%\n",
    "Epoch  66/200, val loss: 3.5e-03, accuracy: 87.20%\n",
    "Epoch  67/200, train loss: 1.6e-03, accuracy: 92.64%\n",
    "Epoch  67/200, val loss: 3.9e-03, accuracy: 86.70%\n",
    "Epoch  68/200, train loss: 1.6e-03, accuracy: 93.03%\n",
    "Epoch  68/200, val loss: 4.1e-03, accuracy: 85.72%\n",
    "Epoch  69/200, train loss: 1.6e-03, accuracy: 92.68%\n",
    "Epoch  69/200, val loss: 3.5e-03, accuracy: 87.46%\n",
    "Epoch  70/200, train loss: 1.6e-03, accuracy: 92.87%\n",
    "Epoch  70/200, val loss: 4.0e-03, accuracy: 86.64%\n",
    "Epoch  71/200, train loss: 1.6e-03, accuracy: 92.89%\n",
    "Epoch  71/200, val loss: 2.8e-03, accuracy: 88.66%\n",
    "Epoch  72/200, train loss: 1.6e-03, accuracy: 92.94%\n",
    "Epoch  72/200, val loss: 3.6e-03, accuracy: 87.22%\n",
    "Epoch  73/200, train loss: 1.6e-03, accuracy: 92.82%\n",
    "Epoch  73/200, val loss: 3.9e-03, accuracy: 85.52%\n",
    "Epoch  74/200, train loss: 1.6e-03, accuracy: 92.81%\n",
    "Epoch  74/200, val loss: 3.3e-03, accuracy: 88.00%\n",
    "Epoch  75/200, train loss: 1.6e-03, accuracy: 92.99%\n",
    "Epoch  75/200, val loss: 4.1e-03, accuracy: 86.18%\n",
    "Epoch  76/200, train loss: 1.6e-03, accuracy: 93.01%\n",
    "Epoch  76/200, val loss: 3.3e-03, accuracy: 87.54%\n",
    "Epoch  77/200, train loss: 1.5e-03, accuracy: 93.26%\n",
    "Epoch  77/200, val loss: 3.5e-03, accuracy: 87.04%\n",
    "Epoch  78/200, train loss: 1.5e-03, accuracy: 93.12%\n",
    "Epoch  78/200, val loss: 3.8e-03, accuracy: 86.72%\n",
    "Epoch  79/200, train loss: 1.6e-03, accuracy: 92.83%\n",
    "Epoch  79/200, val loss: 3.4e-03, accuracy: 87.48%\n",
    "Epoch  80/200, train loss: 1.5e-03, accuracy: 93.08%\n",
    "Epoch  80/200, val loss: 4.0e-03, accuracy: 85.72%\n",
    "Epoch  81/200, train loss: 1.5e-03, accuracy: 93.21%\n",
    "Epoch  81/200, val loss: 3.9e-03, accuracy: 85.80%\n",
    "Epoch  82/200, train loss: 1.6e-03, accuracy: 93.00%\n",
    "Epoch  82/200, val loss: 4.2e-03, accuracy: 85.98%\n",
    "Epoch  83/200, train loss: 1.5e-03, accuracy: 93.14%\n",
    "Epoch  83/200, val loss: 3.5e-03, accuracy: 87.20%\n",
    "Epoch  84/200, train loss: 1.5e-03, accuracy: 93.33%\n",
    "Epoch  84/200, val loss: 4.1e-03, accuracy: 85.00%\n",
    "Epoch  85/200, train loss: 1.5e-03, accuracy: 93.18%\n",
    "Epoch  85/200, val loss: 3.8e-03, accuracy: 86.76%\n",
    "Epoch  86/200, train loss: 1.5e-03, accuracy: 93.29%\n",
    "Epoch  86/200, val loss: 3.7e-03, accuracy: 86.20%\n",
    "Epoch  87/200, train loss: 1.5e-03, accuracy: 93.25%\n",
    "Epoch  87/200, val loss: 4.3e-03, accuracy: 84.40%\n",
    "Epoch  88/200, train loss: 1.5e-03, accuracy: 93.38%\n",
    "Epoch  88/200, val loss: 3.0e-03, accuracy: 88.22%\n",
    "Epoch  89/200, train loss: 1.5e-03, accuracy: 93.23%\n",
    "Epoch  89/200, val loss: 4.4e-03, accuracy: 84.72%\n",
    "Epoch  90/200, train loss: 1.5e-03, accuracy: 93.38%\n",
    "Epoch  90/200, val loss: 3.3e-03, accuracy: 87.74%\n",
    "Epoch  91/200, train loss: 1.5e-03, accuracy: 93.37%\n",
    "Epoch  91/200, val loss: 3.5e-03, accuracy: 87.40%\n",
    "Epoch  92/200, train loss: 1.5e-03, accuracy: 93.14%\n",
    "Epoch  92/200, val loss: 3.1e-03, accuracy: 88.14%\n",
    "Epoch  93/200, train loss: 1.4e-03, accuracy: 93.72%\n",
    "Epoch  93/200, val loss: 5.1e-03, accuracy: 83.62%\n",
    "Epoch  94/200, train loss: 1.5e-03, accuracy: 93.35%\n",
    "Epoch  94/200, val loss: 3.4e-03, accuracy: 88.48%\n",
    "Epoch  95/200, train loss: 1.5e-03, accuracy: 93.31%\n",
    "Epoch  95/200, val loss: 4.2e-03, accuracy: 85.68%\n",
    "Epoch  96/200, train loss: 1.4e-03, accuracy: 93.53%\n",
    "Epoch  96/200, val loss: 3.9e-03, accuracy: 85.98%\n",
    "Epoch  97/200, train loss: 1.5e-03, accuracy: 93.32%\n",
    "Epoch  97/200, val loss: 3.6e-03, accuracy: 86.72%\n",
    "Epoch  98/200, train loss: 1.4e-03, accuracy: 93.67%\n",
    "Epoch  98/200, val loss: 4.3e-03, accuracy: 85.36%\n",
    "Epoch  99/200, train loss: 1.4e-03, accuracy: 93.58%\n",
    "Epoch  99/200, val loss: 3.8e-03, accuracy: 86.92%\n",
    "Epoch 100/200, train loss: 1.4e-03, accuracy: 93.34%\n",
    "Epoch 100/200, val loss: 4.2e-03, accuracy: 85.32%\n",
    "Epoch 101/200, train loss: 8.0e-04, accuracy: 96.59%\n",
    "Epoch 101/200, val loss: 2.3e-03, accuracy: 91.84%\n",
    "Epoch 102/200, train loss: 5.8e-04, accuracy: 97.70%\n",
    "Epoch 102/200, val loss: 2.4e-03, accuracy: 92.06%\n",
    "Epoch 103/200, train loss: 4.9e-04, accuracy: 97.99%\n",
    "Epoch 103/200, val loss: 2.3e-03, accuracy: 92.20%\n",
    "Epoch 104/200, train loss: 4.6e-04, accuracy: 98.11%\n",
    "Epoch 104/200, val loss: 2.4e-03, accuracy: 92.10%\n",
    "Epoch 105/200, train loss: 4.2e-04, accuracy: 98.31%\n",
    "Epoch 105/200, val loss: 2.5e-03, accuracy: 92.22%\n",
    "Epoch 106/200, train loss: 3.9e-04, accuracy: 98.40%\n",
    "Epoch 106/200, val loss: 2.5e-03, accuracy: 92.42%\n",
    "Epoch 107/200, train loss: 3.5e-04, accuracy: 98.60%\n",
    "Epoch 107/200, val loss: 2.4e-03, accuracy: 92.38%\n",
    "Epoch 108/200, train loss: 3.5e-04, accuracy: 98.53%\n",
    "Epoch 108/200, val loss: 2.5e-03, accuracy: 92.34%\n",
    "Epoch 109/200, train loss: 3.1e-04, accuracy: 98.79%\n",
    "Epoch 109/200, val loss: 2.4e-03, accuracy: 92.08%\n",
    "Epoch 110/200, train loss: 3.0e-04, accuracy: 98.85%\n",
    "Epoch 110/200, val loss: 2.5e-03, accuracy: 92.22%\n",
    "Epoch 111/200, train loss: 2.8e-04, accuracy: 98.89%\n",
    "Epoch 111/200, val loss: 2.5e-03, accuracy: 92.44%\n",
    "Epoch 112/200, train loss: 2.6e-04, accuracy: 98.94%\n",
    "Epoch 112/200, val loss: 2.6e-03, accuracy: 92.32%\n",
    "Epoch 113/200, train loss: 2.5e-04, accuracy: 99.02%\n",
    "Epoch 113/200, val loss: 2.6e-03, accuracy: 92.34%\n",
    "Epoch 114/200, train loss: 2.5e-04, accuracy: 99.05%\n",
    "Epoch 114/200, val loss: 2.7e-03, accuracy: 91.90%\n",
    "Epoch 115/200, train loss: 2.4e-04, accuracy: 99.08%\n",
    "Epoch 115/200, val loss: 2.6e-03, accuracy: 92.38%\n",
    "Epoch 116/200, train loss: 2.1e-04, accuracy: 99.20%\n",
    "Epoch 116/200, val loss: 2.6e-03, accuracy: 92.20%\n",
    "Epoch 117/200, train loss: 2.1e-04, accuracy: 99.17%\n",
    "Epoch 117/200, val loss: 2.7e-03, accuracy: 92.30%\n",
    "Epoch 118/200, train loss: 2.2e-04, accuracy: 99.16%\n",
    "Epoch 118/200, val loss: 2.6e-03, accuracy: 92.46%\n",
    "Epoch 119/200, train loss: 2.1e-04, accuracy: 99.22%\n",
    "Epoch 119/200, val loss: 2.7e-03, accuracy: 92.14%\n",
    "Epoch 120/200, train loss: 1.9e-04, accuracy: 99.26%\n",
    "Epoch 120/200, val loss: 2.7e-03, accuracy: 92.32%\n",
    "Epoch 121/200, train loss: 1.9e-04, accuracy: 99.31%\n",
    "Epoch 121/200, val loss: 2.7e-03, accuracy: 92.52%\n",
    "Epoch 122/200, train loss: 1.8e-04, accuracy: 99.33%\n",
    "Epoch 122/200, val loss: 2.7e-03, accuracy: 92.18%\n",
    "Epoch 123/200, train loss: 1.7e-04, accuracy: 99.36%\n",
    "Epoch 123/200, val loss: 2.7e-03, accuracy: 92.16%\n",
    "Epoch 124/200, train loss: 1.6e-04, accuracy: 99.38%\n",
    "Epoch 124/200, val loss: 2.7e-03, accuracy: 92.22%\n",
    "Epoch 125/200, train loss: 1.7e-04, accuracy: 99.38%\n",
    "Epoch 125/200, val loss: 2.8e-03, accuracy: 92.42%\n",
    "Epoch 126/200, train loss: 1.5e-04, accuracy: 99.44%\n",
    "Epoch 126/200, val loss: 2.8e-03, accuracy: 92.40%\n",
    "Epoch 127/200, train loss: 1.5e-04, accuracy: 99.51%\n",
    "Epoch 127/200, val loss: 2.8e-03, accuracy: 92.12%\n",
    "Epoch 128/200, train loss: 1.4e-04, accuracy: 99.51%\n",
    "Epoch 128/200, val loss: 2.8e-03, accuracy: 92.56%\n",
    "Epoch 129/200, train loss: 1.4e-04, accuracy: 99.46%\n",
    "Epoch 129/200, val loss: 2.9e-03, accuracy: 92.24%\n",
    "Epoch 130/200, train loss: 1.4e-04, accuracy: 99.47%\n",
    "Epoch 130/200, val loss: 2.9e-03, accuracy: 92.48%\n",
    "Epoch 131/200, train loss: 1.4e-04, accuracy: 99.50%\n",
    "Epoch 131/200, val loss: 2.9e-03, accuracy: 92.06%\n",
    "Epoch 132/200, train loss: 1.3e-04, accuracy: 99.55%\n",
    "Epoch 132/200, val loss: 2.8e-03, accuracy: 92.52%\n",
    "Epoch 133/200, train loss: 1.2e-04, accuracy: 99.57%\n",
    "Epoch 133/200, val loss: 2.8e-03, accuracy: 92.86%\n",
    "Epoch 134/200, train loss: 1.3e-04, accuracy: 99.52%\n",
    "Epoch 134/200, val loss: 2.9e-03, accuracy: 92.72%\n",
    "Epoch 135/200, train loss: 1.3e-04, accuracy: 99.54%\n",
    "Epoch 135/200, val loss: 2.8e-03, accuracy: 92.68%\n",
    "Epoch 136/200, train loss: 1.2e-04, accuracy: 99.58%\n",
    "Epoch 136/200, val loss: 2.8e-03, accuracy: 92.56%\n",
    "Epoch 137/200, train loss: 1.1e-04, accuracy: 99.60%\n",
    "Epoch 137/200, val loss: 2.9e-03, accuracy: 92.42%\n",
    "Epoch 138/200, train loss: 1.1e-04, accuracy: 99.61%\n",
    "Epoch 138/200, val loss: 3.0e-03, accuracy: 92.22%\n",
    "Epoch 139/200, train loss: 1.1e-04, accuracy: 99.59%\n",
    "Epoch 139/200, val loss: 3.0e-03, accuracy: 92.42%\n",
    "Epoch 140/200, train loss: 1.2e-04, accuracy: 99.61%\n",
    "Epoch 140/200, val loss: 3.0e-03, accuracy: 92.54%\n",
    "Epoch 141/200, train loss: 1.0e-04, accuracy: 99.67%\n",
    "Epoch 141/200, val loss: 2.9e-03, accuracy: 92.54%\n",
    "Epoch 142/200, train loss: 1.1e-04, accuracy: 99.66%\n",
    "Epoch 142/200, val loss: 3.0e-03, accuracy: 92.38%\n",
    "Epoch 143/200, train loss: 1.1e-04, accuracy: 99.61%\n",
    "Epoch 143/200, val loss: 3.0e-03, accuracy: 92.68%\n",
    "Epoch 144/200, train loss: 1.1e-04, accuracy: 99.64%\n",
    "Epoch 144/200, val loss: 3.0e-03, accuracy: 92.30%\n",
    "Epoch 145/200, train loss: 9.6e-05, accuracy: 99.65%\n",
    "Epoch 145/200, val loss: 3.1e-03, accuracy: 92.34%\n",
    "Epoch 146/200, train loss: 9.6e-05, accuracy: 99.69%\n",
    "Epoch 146/200, val loss: 3.0e-03, accuracy: 92.60%\n",
    "Epoch 147/200, train loss: 1.0e-04, accuracy: 99.63%\n",
    "Epoch 147/200, val loss: 3.1e-03, accuracy: 92.42%\n",
    "Epoch 148/200, train loss: 9.4e-05, accuracy: 99.69%\n",
    "Epoch 148/200, val loss: 3.0e-03, accuracy: 92.50%\n",
    "Epoch 149/200, train loss: 9.8e-05, accuracy: 99.66%\n",
    "Epoch 149/200, val loss: 3.2e-03, accuracy: 92.40%\n",
    "Epoch 150/200, train loss: 9.7e-05, accuracy: 99.67%\n",
    "Epoch 150/200, val loss: 3.0e-03, accuracy: 92.44%\n",
    "Epoch 151/200, train loss: 8.0e-05, accuracy: 99.74%\n",
    "Epoch 151/200, val loss: 3.0e-03, accuracy: 92.66%\n",
    "Epoch 152/200, train loss: 7.5e-05, accuracy: 99.79%\n",
    "Epoch 152/200, val loss: 3.0e-03, accuracy: 92.50%\n",
    "Epoch 153/200, train loss: 7.4e-05, accuracy: 99.79%\n",
    "Epoch 153/200, val loss: 3.0e-03, accuracy: 92.58%\n",
    "Epoch 154/200, train loss: 7.3e-05, accuracy: 99.76%\n",
    "Epoch 154/200, val loss: 3.0e-03, accuracy: 92.60%\n",
    "Epoch 155/200, train loss: 7.0e-05, accuracy: 99.80%\n",
    "Epoch 155/200, val loss: 3.0e-03, accuracy: 92.52%\n",
    "Epoch 156/200, train loss: 6.7e-05, accuracy: 99.82%\n",
    "Epoch 156/200, val loss: 3.0e-03, accuracy: 92.46%\n",
    "Epoch 157/200, train loss: 7.6e-05, accuracy: 99.78%\n",
    "Epoch 157/200, val loss: 3.0e-03, accuracy: 92.60%\n",
    "Epoch 158/200, train loss: 6.5e-05, accuracy: 99.82%\n",
    "Epoch 158/200, val loss: 3.0e-03, accuracy: 92.60%\n",
    "Epoch 159/200, train loss: 6.4e-05, accuracy: 99.83%\n",
    "Epoch 159/200, val loss: 3.0e-03, accuracy: 92.58%\n",
    "Epoch 160/200, train loss: 6.9e-05, accuracy: 99.81%\n",
    "Epoch 160/200, val loss: 3.0e-03, accuracy: 92.62%\n",
    "Epoch 161/200, train loss: 6.6e-05, accuracy: 99.80%\n",
    "Epoch 161/200, val loss: 3.0e-03, accuracy: 92.80%\n",
    "Epoch 162/200, train loss: 6.2e-05, accuracy: 99.85%\n",
    "Epoch 162/200, val loss: 3.0e-03, accuracy: 92.66%\n",
    "Epoch 163/200, train loss: 6.5e-05, accuracy: 99.81%\n",
    "Epoch 163/200, val loss: 3.0e-03, accuracy: 92.50%\n",
    "Epoch 164/200, train loss: 6.8e-05, accuracy: 99.79%\n",
    "Epoch 164/200, val loss: 3.0e-03, accuracy: 92.70%\n",
    "Epoch 165/200, train loss: 6.3e-05, accuracy: 99.82%\n",
    "Epoch 165/200, val loss: 3.0e-03, accuracy: 92.68%\n",
    "Epoch 166/200, train loss: 6.4e-05, accuracy: 99.82%\n",
    "Epoch 166/200, val loss: 3.0e-03, accuracy: 92.60%\n",
    "Epoch 167/200, train loss: 6.9e-05, accuracy: 99.79%\n",
    "Epoch 167/200, val loss: 3.0e-03, accuracy: 92.70%\n",
    "Epoch 168/200, train loss: 6.2e-05, accuracy: 99.81%\n",
    "Epoch 168/200, val loss: 3.0e-03, accuracy: 92.62%\n",
    "Epoch 169/200, train loss: 5.9e-05, accuracy: 99.84%\n",
    "Epoch 169/200, val loss: 3.0e-03, accuracy: 92.68%\n",
    "Epoch 170/200, train loss: 6.5e-05, accuracy: 99.82%\n",
    "Epoch 170/200, val loss: 3.0e-03, accuracy: 92.50%\n",
    "Epoch 171/200, train loss: 6.1e-05, accuracy: 99.85%\n",
    "Epoch 171/200, val loss: 3.0e-03, accuracy: 92.72%\n",
    "Epoch 172/200, train loss: 6.3e-05, accuracy: 99.81%\n",
    "Epoch 172/200, val loss: 3.0e-03, accuracy: 92.72%\n",
    "Epoch 173/200, train loss: 5.9e-05, accuracy: 99.84%\n",
    "Epoch 173/200, val loss: 3.0e-03, accuracy: 92.74%\n",
    "Epoch 174/200, train loss: 6.0e-05, accuracy: 99.83%\n",
    "Epoch 174/200, val loss: 3.0e-03, accuracy: 92.80%\n",
    "Epoch 175/200, train loss: 6.0e-05, accuracy: 99.84%\n",
    "Epoch 175/200, val loss: 3.0e-03, accuracy: 92.56%\n",
    "Epoch 176/200, train loss: 6.2e-05, accuracy: 99.84%\n",
    "Epoch 176/200, val loss: 3.0e-03, accuracy: 92.50%\n",
    "Epoch 177/200, train loss: 5.9e-05, accuracy: 99.85%\n",
    "Epoch 177/200, val loss: 3.0e-03, accuracy: 92.54%\n",
    "Epoch 178/200, train loss: 5.6e-05, accuracy: 99.85%\n",
    "Epoch 178/200, val loss: 3.0e-03, accuracy: 92.68%\n",
    "Epoch 179/200, train loss: 6.1e-05, accuracy: 99.81%\n",
    "Epoch 179/200, val loss: 3.0e-03, accuracy: 92.50%\n",
    "Epoch 180/200, train loss: 6.3e-05, accuracy: 99.83%\n",
    "Epoch 180/200, val loss: 3.0e-03, accuracy: 92.52%\n",
    "Epoch 181/200, train loss: 6.4e-05, accuracy: 99.82%\n",
    "Epoch 181/200, val loss: 3.0e-03, accuracy: 92.78%\n",
    "Epoch 182/200, train loss: 6.2e-05, accuracy: 99.84%\n",
    "Epoch 182/200, val loss: 3.0e-03, accuracy: 92.56%\n",
    "Epoch 183/200, train loss: 6.0e-05, accuracy: 99.84%\n",
    "Epoch 183/200, val loss: 3.0e-03, accuracy: 92.58%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_epoch(model, optimizer, dataloader, train):\n",
    "    \"\"\"\n",
    "    Run one epoch of training or evaluation.\n",
    "    \n",
    "    Args:\n",
    "        model: The model used for prediction\n",
    "        optimizer: Optimization algorithm for the model\n",
    "        dataloader: Dataloader providing the data to run our model on\n",
    "        train: Whether this epoch is used for training or evaluation\n",
    "        \n",
    "    Returns:\n",
    "        Loss and accuracy in this epoch.\n",
    "    \"\"\"\n",
    "    # TODO: Change the necessary parts to work correctly during evaluation (train=False)\n",
    "    \n",
    "    device = next(model.parameters()).device\n",
    "    \n",
    "    # Set model to training mode (for e.g. batch normalization, dropout)\n",
    "    \n",
    "    model.train()\n",
    "\n",
    "    epoch_loss = 0.0\n",
    "    epoch_acc = 0.0\n",
    "\n",
    "    # Iterate over data\n",
    "    for xb, yb in dataloader:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward\n",
    "        with torch.set_grad_enabled(True):\n",
    "            pred = model(xb)\n",
    "            loss = F.cross_entropy(pred, yb)\n",
    "            top1 = torch.argmax(pred, dim=1)\n",
    "            ncorrect = torch.sum(top1 == yb)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # statistics\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += ncorrect.item()\n",
    "    \n",
    "    epoch_loss /= len(dataloader.dataset)\n",
    "    epoch_acc /= len(dataloader.dataset)\n",
    "    return epoch_loss, epoch_acc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
